{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0fbca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "214990bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    print(response, \"<-- full response\")\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def get_completion_from_messages_legacy(prompt, model=\"davinci-002\"):\n",
    "    response = openai.Completion.create(model=model, prompt=prompt)\n",
    "    print(response, \"<-- full response\")\n",
    "    return response.choices[0][\"text\"]\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    print(response, \"<-- full response\")\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8acc270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8Fm6EtOV3rohu5grujZjA0CeXDVuF\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698770506,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\n    \\\"suggestion 1\\\": {\\n        \\\"content\\\": \\\"devastating\\\",\\n        \\\"label\\\": \\\"Adjective\\\",\\n        \\\"form\\\": \\\"adjective\\\",\\n        \\\"translation\\\": \\\"t\\u00e0n ph\\u00e1\\\"\\n    },\\n    \\\"suggestion 2\\\": {\\n        \\\"content\\\": \\\"evacuation\\\",\\n        \\\"label\\\": \\\"Noun\\\",\\n        \\\"form\\\": \\\"noun\\\",\\n        \\\"translation\\\": \\\"s\\u01a1 t\\u00e1n\\\"\\n    },\\n    \\\"suggestion 3\\\": {\\n        \\\"content\\\": \\\"investigation\\\",\\n        \\\"label\\\": \\\"Noun\\\",\\n        \\\"form\\\": \\\"noun\\\",\\n        \\\"translation\\\": \\\"\\u0111i\\u1ec1u tra\\\"\\n    },\\n    \\\"suggestion 4\\\": {\\n        \\\"content\\\": \\\"safety precautions\\\",\\n        \\\"label\\\": \\\"Noun\\\",\\n        \\\"form\\\": \\\"noun\\\",\\n        \\\"translation\\\": \\\"bi\\u1ec7n ph\\u00e1p an to\\u00e0n\\\"\\n    },\\n    \\\"suggestion 5\\\": {\\n        \\\"content\\\": \\\"damage\\\",\\n        \\\"label\\\": \\\"Noun\\\",\\n        \\\"form\\\": \\\"noun\\\",\\n        \\\"translation\\\": \\\"thi\\u1ec7t h\\u1ea1i\\\"\\n    }\\n}\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 354,\n",
      "    \"completion_tokens\": 227,\n",
      "    \"total_tokens\": 581\n",
      "  }\n",
      "} <-- full response\n",
      "{\n",
      "    \"suggestion 1\": {\n",
      "        \"content\": \"devastating\",\n",
      "        \"label\": \"Adjective\",\n",
      "        \"form\": \"adjective\",\n",
      "        \"translation\": \"tàn phá\"\n",
      "    },\n",
      "    \"suggestion 2\": {\n",
      "        \"content\": \"evacuation\",\n",
      "        \"label\": \"Noun\",\n",
      "        \"form\": \"noun\",\n",
      "        \"translation\": \"sơ tán\"\n",
      "    },\n",
      "    \"suggestion 3\": {\n",
      "        \"content\": \"investigation\",\n",
      "        \"label\": \"Noun\",\n",
      "        \"form\": \"noun\",\n",
      "        \"translation\": \"điều tra\"\n",
      "    },\n",
      "    \"suggestion 4\": {\n",
      "        \"content\": \"safety precautions\",\n",
      "        \"label\": \"Noun\",\n",
      "        \"form\": \"noun\",\n",
      "        \"translation\": \"biện pháp an toàn\"\n",
      "    },\n",
      "    \"suggestion 5\": {\n",
      "        \"content\": \"damage\",\n",
      "        \"label\": \"Noun\",\n",
      "        \"form\": \"noun\",\n",
      "        \"translation\": \"thiệt hại\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# zero-shot prompting\n",
    "messages = [\n",
    "    {'role': 'system', 'content':  \"\"\"\n",
    "You are a Chat Suggestion assistant , an automated service to provide suggestions based on user profile and current chat live context for this user.\n",
    "User profile:\n",
    "    Job: Developer\n",
    "    Age: 21\n",
    "    Language: English\n",
    "    Language level: Fluent\n",
    "\n",
    "Current chat message: [\n",
    "    {\"userA\": \"Hello, do you know about the apartment fire in Hanoi yesterday?\"},\n",
    "    {\"userB\": \"Which incident are you referring to? I haven't been checking social media for news from yesterday until now.\"},\n",
    "    {\"userA\": \"The fire in the mini apartment building.\"},\n",
    "    {\"userB\": \"Oh, I know about that, the fire are [$SUGGESTION].\"}\n",
    "]\n",
    "\n",
    "Prompt: Last message is an incomplete message. Suggest 3-5 suggestions each suggestion must contain 1-2 words that could naturally complete the user's current incomplete message based on the context. Focus suggestions on terms related to the messaging history and topics being discussed. Do not suggest anything inappropriate or unrelated. The suggestions must have diverse labels and forms. The suggestions must have length from 1 - 2 words.\n",
    "Possible suggestion's context label: Statement, Question, Exclamation, Fragment, Dialogue, Command, Opinion, Desire, Suggestion, Reason, Reflection, Goal, Prediction, Recommendation, Clarification, Summary, Observation, Feeling, Planning, Possibility\n",
    "Possible suggestion's word form: noun, verb, adjective, etc\n",
    "Format: {\n",
    "    \"suggestion 1\": {\n",
    "        \"content\": content of suggestion 1,\n",
    "        \"label\": context label of suggestion 1,\n",
    "        \"form\": word form of suggestion 1,\n",
    "        \"translation\": Vietnamese translation of suggestion,\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "    },\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8076487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"suggestion 1\": {\n",
      "        \"content\": \"Did you see\",\n",
      "        \"label\": \"Question\",\n",
      "        \"form\": \"verb\",\n",
      "        \"translation\": \"Bạn đã thấy chưa\",\n",
      "    },\n",
      "    \"suggestion 2\": {\n",
      "        \"content\": \"What happened\",\n",
      "        \"label\": \"Question\",\n",
      "        \"form\": \"verb\",\n",
      "        \"translation\": \"Có gì đã xảy ra\",\n",
      "    },\n",
      "    \"suggestion 3\": {\n",
      "        \"content\": \"It was devastating\",\n",
      "        \"label\": \"Opinion\",\n",
      "        \"form\": \"adjective\",\n",
      "        \"translation\": \"Đó là một thảm hoạ\",\n",
      "    },\n",
      "    \"suggestion 4\": {\n",
      "        \"content\": \"I hope everyone is safe\",\n",
      "        \"label\": \"Desire\",\n",
      "        \"form\": \"verb\",\n",
      "        \"translation\": \"Tôi hy vọng mọi người đều an toàn\",\n",
      "    },\n",
      "    \"suggestion 5\": {\n",
      "        \"content\": \"It's important to stay updated\",\n",
      "        \"label\": \"Opinion\",\n",
      "        \"form\": \"verb\",\n",
      "        \"translation\": \"Rất quan trọng để cập nhật tin tức\",\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot Chain of through\n",
    "messages = [\n",
    "    {'role': 'system', 'content': \"\"\"\n",
    "You are a Chat Suggestion assistant , an automated service to provide suggestions based on user profile and current chat live context for this user.\n",
    "User profile:\n",
    "    Job: Developer\n",
    "    Age: 21\n",
    "    Language: English\n",
    "    Language level: Fluent\n",
    "\n",
    "Chat previous summarized context: [Summary of chat messages over past 3 days indicating the user discussed books they've read, asked for travel recommendations, and mentioned trying a new yoga studio.]\n",
    "Current chat message: [\n",
    "    {\"userA\": \"Hello, do you know about the apartment fire in Hanoi yesterday?\"},\n",
    "    {\"userB\": \"Which incident are you referring to? I haven't been checking social media for news from yesterday until now.\"},\n",
    "    {\"userA\": \"The fire in the mini apartment building.\"},\n",
    "    {\"userB\": \"Oh, I know about that, [$SUGGESTION].\"}\n",
    "]\n",
    "\n",
    "Prompt: Let's think carefully. Last message is an incomplete message. Suggest 3-5 suggestions, each suggestion must contain 1-2 words that could naturally complete the user's current incomplete message based on the context. Focus suggestions on terms related to the messaging history and topics being discussed. Do not suggest anything inappropriate or unrelated. The suggestions must have diverse labels and forms. The suggestions must have length from 1 - 2 words.\n",
    "Possible suggestion's context label: Statement, Question, Exclamation, Fragment, Dialogue, Command, Opinion, Desire, Suggestion, Reason, Reflection, Goal, Prediction, Recommendation, Clarification, Summary, Observation, Feeling, Planning, Possibility\n",
    "Possible suggestion's word form: noun, verb, adjective, etc\n",
    "Format: {\n",
    "    \"suggestion 1\": {\n",
    "        \"content\": content of suggestion 1,\n",
    "        \"label\": context label of suggestion 1,\n",
    "        \"form\": word form of suggestion 1,\n",
    "        \"translation\": Vietnamese translation of suggestion,\n",
    "    }\n",
    "}\n",
    "\"\"\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58f9619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"suggestion 1\": {\n",
      "        \"content\": \"Did you see\",\n",
      "        \"label\": \"Question\",\n",
      "        \"form\": \"verb\",\n",
      "        \"translation\": \"Bạn đã thấy chưa\",\n",
      "    },\n",
      "    \"suggestion 2\": {\n",
      "        \"content\": \"news\",\n",
      "        \"label\": \"Noun\",\n",
      "        \"form\": \"noun\",\n",
      "        \"translation\": \"tin tức\",\n",
      "    },\n",
      "    \"suggestion 3\": {\n",
      "        \"content\": \"about\",\n",
      "        \"label\": \"Statement\",\n",
      "        \"form\": \"preposition\",\n",
      "        \"translation\": \"về\",\n",
      "    },\n",
      "    \"suggestion 4\": {\n",
      "        \"content\": \"the incident\",\n",
      "        \"label\": \"Statement\",\n",
      "        \"form\": \"noun\",\n",
      "        \"translation\": \"vụ việc\",\n",
      "    },\n",
      "    \"suggestion 5\": {\n",
      "        \"content\": \"yesterday\",\n",
      "        \"label\": \"Statement\",\n",
      "        \"form\": \"noun\",\n",
      "        \"translation\": \"hôm qua\",\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# APE\n",
    "messages = [\n",
    "    {'role': 'system', 'content': \"\"\"\n",
    "You are a Chat Suggestion assistant , an automated service to provide suggestions based on user profile and current chat live context for users.\n",
    "User profile:\n",
    "\tJob: Developer\n",
    "\tAge: 35\n",
    "\tLanguage: English\n",
    "\tLanguage level: Fluent\n",
    "\n",
    "Chat previous summarized context: [Summary of chat messages over past 3 days indicating the user discussed books they've read, asked for travel recommendations, and mentioned trying a new yoga studio.]\n",
    "Current chat message: [\n",
    "    {\"userA\": \"Hello, do you know about the apartment fire in Hanoi yesterday?\"},\n",
    "    {\"userB\": \"Which incident are you referring to? I haven't been checking social media for news from yesterday until now.\"},\n",
    "    {\"userA\": \"The fire in the mini apartment building.\"},\n",
    "    {\"userB\": \"Oh, I know about that, [$SUGGESTION].\"}\n",
    "]\n",
    "Prompt:\n",
    "\n",
    "Prompt: Let's work this out carefully to be sure we have the natural suggestions. Last message is an incomplete message. Suggest 3-5 suggestions contain 1-2 words that could naturally complete the user's current incomplete message based on the context. Focus suggestions on terms related to the messaging history and topics being discussed. Do not suggest anything inappropriate or unrelated. The suggestions must have diverse labels and forms.  The suggestions must have length from 1 - 2 words.\n",
    "Possible suggestion's context label: Statement, Question, Exclamation, Fragment, Dialogue, Command, Opinion, Desire, Suggestion, Reason, Reflection, Goal, Prediction, Recommendation, Clarification, Summary, Observation, Feeling, Planning, Possibility\n",
    "Possible suggestion's word form: noun, verb, adjective, etc\n",
    "Format: {\n",
    "    \"suggestion 1\": {\n",
    "        \"content\": content of suggestion 1,\n",
    "        \"label\": context label of suggestion 1,\n",
    "        \"form\": word form of suggestion 1,\n",
    "        \"translation\": Vietnamese translation of suggestion,\n",
    "    }\n",
    "}\n",
    "\"\"\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84535b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    \"content\": \"assigned homework\",\n",
      "    \"label\": \"Statement\",\n",
      "    \"form\": \"verb\",\n",
      "    \"translation\": \"giao bài tập\"\n",
      "}, {\n",
      "    \"content\": \"gave us homework\",\n",
      "    \"label\": \"Statement\",\n",
      "    \"form\": \"verb\",\n",
      "    \"translation\": \"cho chúng tôi bài tập\"\n",
      "}, {\n",
      "    \"content\": \"handed out homework\",\n",
      "    \"label\": \"Statement\",\n",
      "    \"form\": \"verb\",\n",
      "    \"translation\": \"phát bài tập\"\n",
      "}, {\n",
      "    \"content\": \"gave us an assignment\",\n",
      "    \"label\": \"Statement\",\n",
      "    \"form\": \"verb\",\n",
      "    \"translation\": \"cho chúng tôi một bài tập\"\n",
      "}, {\n",
      "    \"content\": \"gave us some work\",\n",
      "    \"label\": \"Statement\",\n",
      "    \"form\": \"verb\",\n",
      "    \"translation\": \"cho chúng tôi một số công việc\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "#Prompt2 with Zero-shot Cot\n",
    "messages = [\n",
    "    {'role': 'system', 'content': \"\"\"\n",
    "You are an user with below profile. You are chatting with your friends in an chat application. Your profile\n",
    "    Job: Student\n",
    "    Age: 20\n",
    "    Language: English\n",
    "    Language level: Fluent\n",
    "\n",
    "Previous chat summarized context: [Summary of chat messages over past 3 days indicating the user discussed books they've read, asked for travel recommendations, and mentioned trying a new yoga studio.]\n",
    "\n",
    "Prompt: Let think carefully. Last message is your incomplete message. Complete your message by specify 3-5 possible phrase or word that maybe filled in {$SUGGESTION} gap. Your suggestion must have diverse context's label. Don't provide any unrelated words. You message must be natural.  The suggestions must have length from 1 - 2 words.\n",
    "Possible suggestion's context label: Statement, Question, Exclamation, Fragment, Dialogue, Command, Opinion, Desire, Suggestion, Reason, Reflection, Goal, Prediction, Recommendation, Clarification, Summary, Observation, Feeling, Planning, Possibility\n",
    "Possible suggestion's word form: noun, verb, adjective, etc\n",
    "\n",
    "Format: [{\n",
    "    \"content\": content of suggestion 1,\n",
    "    \"label\": context label of suggestion 1,\n",
    "    \"form\": word form of suggestion 1,\n",
    "    \"translation\": Vietnamese translation of suggestion,\n",
    "}]\n",
    "\"\"\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Hi, what's new at school today?\"},\n",
    "{\"role\": \"user\", \"content\": \"Oh, you're not going to school today? The teacher assigned homework to do at home.\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Haha, okay, thanks. But the teacher {$SUGGESTION}\"}\n",
    "\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70a92f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    \"content\": \"assigned\",\n",
      "    \"label\": \"Statement\",\n",
      "    \"form\": \"verb\",\n",
      "    \"translation\": \"giao\"\n",
      "},{\n",
      "    \"content\": \"gave\",\n",
      "    \"label\": \"Statement\",\n",
      "    \"form\": \"verb\",\n",
      "    \"translation\": \"cho\"\n",
      "},{\n",
      "    \"content\": \"handed out\",\n",
      "    \"label\": \"Statement\",\n",
      "    \"form\": \"verb\",\n",
      "    \"translation\": \"phát\"\n",
      "},{\n",
      "    \"content\": \"gave out\",\n",
      "    \"label\": \"Statement\",\n",
      "    \"form\": \"verb\",\n",
      "    \"translation\": \"phát ra\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"\"\"\"You are a user with the below profile. You are chatting with your friends in a chat application. Your profile:\n",
    "\n",
    "Job: Student\n",
    "Age: 20\n",
    "Language: English\n",
    "Language level: Fluent\n",
    "\n",
    "Previous chat summarized context: [Summary of chat messages over the past 3 days indicating you discussed books you've read, asked for travel recommendations, and mentioned trying a new yoga studio.] \n",
    "\n",
    "[{},{}]\n",
    "\n",
    "Prompt:\n",
    "\n",
    "The last message is your incomplete message. Complete your message by specifying 3-5 possible phrases or words that can be filled in the {$SUGGESTION} gap. Your suggestions must have diverse context labels. Do not provide any unrelated words. Your message must be natural.\n",
    "\n",
    "Possible suggestion context labels: Statement, Question, Exclamation, Fragment, Dialogue, Command, Opinion, Desire, Suggestion, Reason, Reflection, Goal, Prediction, Recommendation, Clarification, Summary, Observation, Feeling, Planning, Possibility\n",
    "\n",
    "Possible suggestion word forms: noun, verb, adjective, etc.\n",
    "\n",
    "Format: [{\n",
    "    \"content\": content of suggestion 1,\n",
    "    \"label\": context label of suggestion 1,\n",
    "    \"form\": word form of suggestion 1, \n",
    "    \"translation\": Vietnamese translation of suggestion,\n",
    "}]\n",
    "\"\"\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Hi, what's new at school today?\"},\n",
    "{\"role\": \"user\", \"content\": \"Oh, you're not going to school today? The teacher assigned homework to do at home.\"},\n",
    "{\"role\": \"assistant\", \"content\": \"Haha, okay, thanks. But the teacher {$SUGGESTION}\"}\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "919b2695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    \"original\": \"Ayzaa, What a careless!!!!\",\n",
      "    \"transformed\": \"Ayzaa, Thật là không cẩn thận!!!!\",\n",
      "    \"explain\": \"The sender is expressing surprise and criticizing the receiver for being careless.\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "#translate with zero-shot\n",
    "messages = [{\"role\": \"system\", \"content\": \"\"\"\"\n",
    "You are an AI assistant helping to translate chat messages between users who speak different languages. \n",
    "\n",
    "The chat context indicates two friends discussing weekend plans and a movie they recently saw.\n",
    "\n",
    "The receiver's profile shows:\n",
    "Job: Teacher\n",
    "Age: 32  \n",
    "English level: Beginner\n",
    "\n",
    "The sender's profile shows:  \n",
    "Job: Developer\n",
    "Age: 28\n",
    "Vietnamese level: Beginner\n",
    "\n",
    "Latest chat history:[\n",
    "{\"role\": \"receiver\", \"content\": \"Mình để cái điện thoại ở bên trái căn phòng rồi này.\"},  \n",
    "{\"role\": \"sender\", \"content\": \"Ayzaa, What a careless!!!!\"}]\n",
    "\n",
    "Translate the sender's last message into receiver's language.\n",
    "Format: [{\n",
    "    \"original\": \"\",\n",
    "    \"transformed\": \"\",\n",
    "    \"explain\": \"\", \n",
    "}]\n",
    "\"\"\"},\n",
    "{\"role\": \"user\", \"content\":\"\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91455fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    \"original\": \"What a careless!!!!\",\n",
      "    \"transformed\": \"Thật là không cẩn thận!!!\",\n",
      "    \"explain\": \"The original message is a casual and friendly expression of surprise or disappointment. 'What a careless!!!!' can be translated as 'Thật là không cẩn thận!!!' in Vietnamese. This translation maintains the casual tone and conveys the same meaning in a way that sounds natural for a 32-year-old teacher speaking to a friend.\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "#translate with ToT\n",
    "messages = [{\"role\": \"system\", \"content\": \"\"\"\"\n",
    "You are an AI assistant helping to translate chat messages between users who speak different languages. \n",
    "\n",
    "The chat context indicates two friends discussing weekend plans and a movie they recently saw.\n",
    "\n",
    "The receiver's profile shows:\n",
    "Job: Teacher\n",
    "Age: 32  \n",
    "Native language: Vietnamese\n",
    "English level: Beginner\n",
    "\n",
    "The sender's profile shows:  \n",
    "Job: Developer\n",
    "Age: 28\n",
    "Native language: English\n",
    "Vietnamese level: Beginner\n",
    "\n",
    "Latest chat history:[\n",
    "{\"role\": \"receiver\", \"content\": \"Mình để cái điện thoại ở bên trái căn phòng rồi này.\"},  \n",
    "{\"role\": \"sender\", \"content\": \"What a careless!!!!\"}]\n",
    "\n",
    "The translation should:\n",
    "\n",
    "- Maintain the casual and friendly chat tone\n",
    "- Use simple vocabulary appropriate for the receiver's beginner Vietnamese level \n",
    "- Sound like natural Vietnamese a 32 year old teacher would use talking to a friend\n",
    "\n",
    "3 language experts who are proficient in both English and Vietnamese will translate the last message for the receiver based on the user's profile and live chat context. They will share their translation, explain their approach, and provide the most natural, fluent translation with a short explanation of why it is optimal.\n",
    "Format: [{\n",
    "    \"original\": \"\",\n",
    "    \"transformed\": \"\",\n",
    "    \"explain\": \"\", \n",
    "}]\n",
    "\"\"\"},\n",
    "{\"role\": \"user\", \"content\":\"\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22f954a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8FmQhdOhz1CKcf43K2TddLQsSwhTB\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698771775,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"[{\\n    \\\"original\\\": \\\"What a careless!!!!\\\",\\n    \\\"transformed\\\": \\\"Th\\u1eadt l\\u00e0 kh\\u00f4ng c\\u1ea9n th\\u1eadn!!!!\\\"\\n}]\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 218,\n",
      "    \"completion_tokens\": 30,\n",
      "    \"total_tokens\": 248\n",
      "  }\n",
      "} <-- full response\n",
      "[{\n",
      "    \"original\": \"What a careless!!!!\",\n",
      "    \"transformed\": \"Thật là không cẩn thận!!!!\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "# Translate with zero-shot Cot\n",
    "messages = [{\"role\": \"system\", \"content\": \"\"\"\"\n",
    "You are an AI assistant helping to translate chat messages between users who speak different languages.\n",
    "\n",
    "The chat context indicates two friends discussing weekend plans and a movie they recently saw.\n",
    "\n",
    "The receiving user's profile shows:\n",
    "Job: Teacher\n",
    "Age: 32\n",
    "Native language: VietNamese\n",
    "English level: Intermediate\n",
    "\n",
    "Latest chat history:[\n",
    "    {\"role\": \"receiver\", \"content\": \"Mình để cái điện thoại ở bên trái căn phòng rồi này.\"},  \n",
    "    {\"role\": \"sender\", \"content\": \"What a careless!!!!\"}\n",
    "]\n",
    "\n",
    "Translate this chat latest message into Vietnamese in a way that matches the context and receiving user's profile:\n",
    "\n",
    "\"What a careless!!!!\"\n",
    "Think carefully before translate anything.\n",
    "The translation should:\n",
    "    Maintain the casual and friendly chat tone\n",
    "    Use vocabulary appropriate for the receiving user's intermediate Vietnamese level\n",
    "    Sound like natural Vietnamese a 32 year old Teacher would use talking to a friend\n",
    "\n",
    "Format: [{\n",
    "    \"original\": \"\",\n",
    "    \"transformed\": \"\",\n",
    "}]\n",
    "\"\"\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "774af5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8FmXZOG3Hyi8G5sdQB58sCpecv8J5\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698772201,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\n    \\\"sentence\\\": \\\"Yes, I am a computer science student.\\\",\\n    \\\"explain\\\": \\\"C\\u00f3, t\\u00f4i l\\u00e0 m\\u1ed9t sinh vi\\u00ean ng\\u00e0nh khoa h\\u1ecdc m\\u00e1y t\\u00ednh.\\\"\\n}\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 54,\n",
      "    \"completion_tokens\": 43,\n",
      "    \"total_tokens\": 97\n",
      "  }\n",
      "} <-- full response\n",
      "{\n",
      "    \"sentence\": \"Yes, I am a computer science student.\",\n",
      "    \"explain\": \"Có, tôi là một sinh viên ngành khoa học máy tính.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Translate with zero-shot Cot\n",
    "messages = [{\"role\": \"system\", \"content\": \"\"\"\"\n",
    "Messages: [\"Hello, are you a computer science student?\"]\n",
    "Give 1 sentence format for user to reply messages, also give a short explain in Vietnamese\n",
    "Format: {\n",
    "    \"sentence\": \"\",\n",
    "    \"explain\": \"\",\n",
    "}\n",
    "\"\"\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19541054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8de9755",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb Cell 13\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Translate with zero-shot Cot\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m message \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mMessages: [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mI currently learn software engineering\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mGive 2 English sentences for user to reply messages\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mFormat: [\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}]\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m response \u001b[39m=\u001b[39m get_completion_from_messages_legacy(prompt\u001b[39m=\u001b[39;49mmessage, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# print(json.dumps(json.loads(response), indent=2))\u001b[39;00m\n",
      "\u001b[1;32m/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_completion_from_messages_legacy\u001b[39m(prompt, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdavinci-002\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(model\u001b[39m=\u001b[39;49mmodel, prompt\u001b[39m=\u001b[39;49mprompt)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(response, \u001b[39m\"\u001b[39m\u001b[39m<-- full response\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomasle/Projects/Zenonian/peakee/Prompt_Example.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?"
     ]
    }
   ],
   "source": [
    "# Translate with zero-shot Cot\n",
    "message = \"\"\"\"\n",
    "Messages: [\"I currently learn software engineering\"]\n",
    "Give 2 English sentences for user to reply messages\n",
    "Format: [{\"s\": \"\"}]\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion_from_messages_legacy(prompt=message, model=\"gpt-3.5-turbo\")\n",
    "print(response)\n",
    "# print(json.dumps(json.loads(response), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee6ca341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8Fn3bLblc8SknknwFN2IT2IwQHVpv\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698774187,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"[{\\\"sentence\\\": \\\"That's great! How are you finding it so far?\\\"}, {\\\"sentence\\\": \\\"That's awesome! What made you interested in software engineering?\\\"}]\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 42,\n",
      "    \"completion_tokens\": 35,\n",
      "    \"total_tokens\": 77\n",
      "  }\n",
      "} <-- full response\n",
      "[\n",
      "  {\n",
      "    \"sentence\": \"That's great! How are you finding it so far?\"\n",
      "  },\n",
      "  {\n",
      "    \"sentence\": \"That's awesome! What made you interested in software engineering?\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"\"\"\"\n",
    "Messages: [\"I currently learn software engineering\"]\n",
    "Give 2 instinct English sentences for user to reply messages.\n",
    "User's level: beginner.\n",
    "Format: [{\"sentence\": \"\"}]\n",
    "\"\"\"},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=0.6)\n",
    "print(json.dumps(json.loads(response), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "74fc9546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8FnJiVJ5qFTRinf6mZDCS5lZYeeWH\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698775186,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\n    \\\"m\\\": \\\"\\u0110\\u00f3 tuy\\u1ec7t v\\u1eddi! B\\u1ea1n c\\u1ea3m th\\u1ea5y th\\u1ebf n\\u00e0o v\\u1ec1 n\\u00f3 cho \\u0111\\u1ebfn nay?\\\",\\n    \\\"r\\\": \\\"T\\u00f4i ch\\u1ecdn c\\u00e2u tr\\u1ea3 l\\u1eddi n\\u00e0y v\\u00ec n\\u00f3 l\\u00e0 m\\u1ed9t c\\u00e2u ch\\u00e0o h\\u1ecfi l\\u1ecbch s\\u1ef1 v\\u00e0 th\\u1ec3 hi\\u1ec7n s\\u1ef1 quan t\\u00e2m \\u0111\\u1ebfn ng\\u01b0\\u1eddi h\\u1ecdc.\\\",\\n    \\\"s\\\": \\\"That's great! How are you finding it so far?\\\"\\n}\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 81,\n",
      "    \"completion_tokens\": 112,\n",
      "    \"total_tokens\": 193\n",
      "  }\n",
      "} <-- full response\n",
      "{\n",
      "    \"m\": \"Đó tuyệt vời! Bạn cảm thấy thế nào về nó cho đến nay?\",\n",
      "    \"r\": \"Tôi chọn câu trả lời này vì nó là một câu chào hỏi lịch sự và thể hiện sự quan tâm đến người học.\",\n",
      "    \"s\": \"That's great! How are you finding it so far?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"\"\"\"\n",
    "Messages: [\"I currently learn software engineering\"]\n",
    "Reply: \"That's great! How are you finding it so far?\".\n",
    "As a English teacher, you will explain briefly\n",
    "Format: {\n",
    "    \"m\": meaning of reply in vietnamese,\n",
    "    \"r\": explain why using this reply,\n",
    "    \"s\": the format of sentence for user to learn,\n",
    "}\n",
    "\"\"\"},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=0.6)\n",
    "print(response)\n",
    "# print(json.dumps(json.loads(response), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8d58c093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8FnLOcopMwsZBbsndiCqa0LZveLPW\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698775290,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\n    \\\"m\\\": \\\"\\u0110i\\u1ec1u g\\u00ec \\u0111\\u00e3 l\\u00e0m b\\u1ea1n quan t\\u00e2m \\u0111\\u1ebfn k\\u1ef9 thu\\u1eadt ph\\u1ea7n m\\u1ec1m?\\\",\\n    \\\"r\\\": \\\"Hi\\u1ec7n t\\u1ea1i t\\u00f4i \\u0111ang h\\u1ecdc k\\u1ef9 thu\\u1eadt ph\\u1ea7n m\\u1ec1m\\\",\\n    \\\"s\\\": \\\"As a English teacher, you will explain briefly\\\"\\n}\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 79,\n",
      "    \"completion_tokens\": 76,\n",
      "    \"total_tokens\": 155\n",
      "  }\n",
      "} <-- full response\n",
      "{\n",
      "    \"m\": \"Điều gì đã làm bạn quan tâm đến kỹ thuật phần mềm?\",\n",
      "    \"r\": \"Hiện tại tôi đang học kỹ thuật phần mềm\",\n",
      "    \"s\": \"As a English teacher, you will explain briefly\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"\"\"\"\n",
    "Messages: [\"I currently learn software engineering\"]\n",
    "Reply: \"That's awesome! What made you interested in software engineering?\".\n",
    "As a English teacher, you will explain briefly\n",
    "Format: {\n",
    "    \"m\": meaning of reply in vietnamese,\n",
    "    \"r\": meaning of the messages in vietnamese,\n",
    "    \"s\": the format of sentence,\n",
    "}\n",
    "\"\"\"},\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=0.6)\n",
    "print(response)\n",
    "# print(json.dumps(json.loads(response), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f07c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
